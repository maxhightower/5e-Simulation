{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFS running combat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series refers to the sequence of subactions and relevant details needed by the process_turn function.\n",
    "\n",
    "A full_list refers to the collection of series options an actor has to pick from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DFS_World_States import world, world_grid_states, Weapon, Potion, Shield, Wand\n",
    "from DFS_Universal_Rules import theoretical_turn_length, subaction_dict, target_distance_scores, fire_bolt, ray_of_frost, shield\n",
    "from DFS_Action_Series import RuleBasedSequenceDFS, action_rules, action_rules_sources\n",
    "from DFS_Location_Series import RuleBasedLocationSequenceDFS2, location_rules, location_rules_sources\n",
    "from DFS_Functions import precalc_reward_series, analyze_reward_distribution, post_loc_series_reward_calc, post_obj_reward_series_calc2, analyze_reward_distribution_series, calc_new_reward\n",
    "from DFS_Object_Series import RuleBasedObjectSequenceDFS1, object_rules, object_rules_sources\n",
    "from DFS_Entity_Series import RuleBasedEntitySequenceDFS, entity_rules, entity_rules_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DFS_Entities import entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = world(11)\n",
    "\n",
    "stage.generate_map()\n",
    "\n",
    "actor = entity('player character',stage,None,'medium')\n",
    "stage.add_entity([0,0],actor)\n",
    "\n",
    "actor.add_spell(fire_bolt)\n",
    "actor.add_spell(ray_of_frost)\n",
    "actor.add_spell(shield)\n",
    "\n",
    "stage.add_item_to_inventory(actor, Weapon('dagger1', 'weapon', 1, 1, 0))\n",
    "stage.add_item_to_inventory(actor, Weapon('dagger2', 'weapon', 1, 1, 0))\n",
    "stage.add_item_to_inventory(actor, Weapon('greataxe', 'weapon', 1, 1, 0))\n",
    "stage.add_item_to_inventory(actor, Shield('shield','shield', 1))\n",
    "stage.add_item_to_inventory(actor, Wand('wand','wand', 1))\n",
    "\n",
    "\n",
    "\n",
    "monster_one = entity('monster',stage,None,'small','goblin','1x1',False,6)\n",
    "stage.add_entity([2,2],monster_one)\n",
    "\n",
    "monster_two = entity('monster',stage,None,'medium','guard','1x1',False,6)\n",
    "stage.add_entity([1,1],monster_two)\n",
    "\n",
    "monster_three = entity('monster',stage,None,'large','horse','2x2',True,12)\n",
    "stage.add_entity([0,-3],monster_three)\n",
    "\n",
    "\n",
    "#stage.add_enemy((-2,0))\n",
    "#stage.add_enemy((0,3))\n",
    "#stage.add_enemy((2,2))\n",
    "#stage.add_enemy((-3,-3))\n",
    "#stage.add_enemy((1,-1))\n",
    "\n",
    "stage.add_coin((3,0))\n",
    "stage.add_coin((-1,-1))\n",
    "stage.add_coin((1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stage.add_weapon_dagger((-2,-1))\n",
    "stage.add_weapon_dagger((-1,-2))\n",
    "stage.add_weapon_greataxe((2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage.grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I should display a visual here of the grid and where each entity and object is located\n",
    "\n",
    "# stage.grid2 is a inhomogeneous list of lists of lists, ints, and strings that represent the grid\n",
    "\n",
    "# I only want to see the entities and objects, so I will create a new list of lists that only contains the entities and objects\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_sequence_generator = RuleBasedSequenceDFS(min_length=0,max_length=theoretical_turn_length, start=0, end=len(subaction_dict), rules=action_rules, acting_entity=actor)\n",
    "action_series_full_list = action_sequence_generator.generate_sequences()\n",
    "#action_series_full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_series_full_list = precalc_reward_series(action_series_full_list, actor)\n",
    "#reward_series_full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 2028956\n",
      "High: 8\n",
      "Low: -2\n",
      "\n",
      "Reward Distribution:\n",
      "% of -2s: 0.06%\n",
      "% of -1s: 1.03%\n",
      "% of 0s: 5.97%\n",
      "% of 1s: 15.89%\n",
      "% of 2s: 31.58%\n",
      "% of 3s: 29.10%\n",
      "% of 4s: 11.64%\n",
      "% of 5s: 3.79%\n",
      "% of 6s: 0.85%\n",
      "% of 7s: 0.08%\n",
      "% of 8s: 0.00%\n",
      "\n",
      "Quality Threshold (99): 5.0\n",
      "Total Qualifiers: 95755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#analyze_reward_distribution(reward_series_full_list, action_series_full_list)\n",
    "action_reward_series_full_list = [[action_series_full_list[i], reward_series_full_list[i]] for i in range(len(action_series_full_list))]\n",
    "\n",
    "analyze_reward_distribution_series(action_reward_series_full_list, actor, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality threshold: 5.0\n"
     ]
    }
   ],
   "source": [
    "location_series_generator = RuleBasedLocationSequenceDFS2(action_series_list=action_series_full_list,\n",
    "                                                             reward_series_list=reward_series_full_list,\n",
    "                                                             location_rules=location_rules,\n",
    "                                                             acting_entity=actor,\n",
    "                                                             target_distance_scores=target_distance_scores)\n",
    "location_series_full_list = location_series_generator.generate_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m post_location_reward_list \u001b[38;5;241m=\u001b[39m \u001b[43mpost_loc_series_reward_calc\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_series_full_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation_series_full_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward_series_full_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maxhi\\OneDrive\\Documents\\GitHub\\5e-Simulation\\DFS_Functions.py:985\u001b[0m, in \u001b[0;36mpost_loc_series_reward_calc\u001b[1;34m(all_action_series, all_location_series, all_reward_series, acting_entity)\u001b[0m\n\u001b[0;32m    982\u001b[0m move_act_loc \u001b[38;5;241m=\u001b[39m ([x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m action_series \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m move_subactions],[loc_series[y] \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loc_series)) \u001b[38;5;28;01mif\u001b[39;00m action_series[y] \u001b[38;5;129;01min\u001b[39;00m move_subactions])\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m#print(f'move act loc: {move_act_loc}')\u001b[39;00m\n\u001b[1;32m--> 985\u001b[0m move_path \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_full_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43macting_entity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmove_act_loc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m#print(f'move path: {move_path}')\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_opportunity_attacks(move_path, acting_entity\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39menemy_locations):\n",
      "File \u001b[1;32mc:\\Users\\maxhi\\OneDrive\\Documents\\GitHub\\5e-Simulation\\DFS_Functions.py:127\u001b[0m, in \u001b[0;36mcalculate_full_path\u001b[1;34m(entity_location, actions_locations_series)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m#print(f'calculated distance: {calculated_distance}')\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# if the distance is greater than 1, then the path needs to be calculated\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calculated_distance \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 127\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mbresenham_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation_pair\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation_pair\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     full_path\u001b[38;5;241m.\u001b[39mextend(path)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\maxhi\\OneDrive\\Documents\\GitHub\\5e-Simulation\\DFS_Functions.py:56\u001b[0m, in \u001b[0;36mbresenham_line\u001b[1;34m(start, end)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbresenham_line\u001b[39m(start, end):\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    Implementation of Bresenham's line algorithm.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    :return: List of tuples representing all points on the line\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     x1, y1 \u001b[38;5;241m=\u001b[39m start\n\u001b[0;32m     57\u001b[0m     x2, y2 \u001b[38;5;241m=\u001b[39m end\n\u001b[0;32m     58\u001b[0m     dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(x2 \u001b[38;5;241m-\u001b[39m x1)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "post_location_reward_list = post_loc_series_reward_calc(action_series_full_list, location_series_full_list, reward_series_full_list, actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_reward_distribution_series(post_location_reward_list, actor, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Series\n",
    "object_series_generator = RuleBasedObjectSequenceDFS1(post_location_reward_list = post_location_reward_list, \n",
    "                                                     target_distance_scores = target_distance_scores,\n",
    "                                                     object_rules = object_rules, \n",
    "                                                     acting_entity = actor)\n",
    "object_series_full_list = object_series_generator.generate_object_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_object_reward_list = post_obj_reward_series_calc2(object_series_full_list, actor)\n",
    "post_object_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_reward_distribution_series(post_object_reward_list, actor, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity series\n",
    "# in order to specify which entity is being targeted\n",
    "\n",
    "# shortcuts:\n",
    "# - currently based on the location series, if there is only one entity in a space, the entity is automatically targeted\n",
    "# - only if there are multiple entities in a space, the entity series is used to determine the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_series_generator = RuleBasedEntitySequenceDFS(action_location_object_reward_series_full_list = post_object_reward_list,\n",
    "                                                     target_distance_scores = target_distance_scores,\n",
    "                                                     entity_rules = entity_rules,\n",
    "                                                     acting_entity = actor)\n",
    "entity_series_generator.generate_entity_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_location_object_entity_reward_series_full_list = entity_series_generator.generate_entity_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_location_object_entity_reward_series_full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_location_object_entity_reward_series_full_list = calc_new_reward(action_location_object_entity_reward_series_full_list, actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_reward_distribution_series(action_location_object_entity_reward_series_full_list, actor, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post_object_reward_list = post_obj_reward_series_calc(action_series_full_list = action_series_full_list, \n",
    "#                                                      location_series_full_list = location_series_full_list, \n",
    "#                                                      object_series_full_list = object_series_full_list, \n",
    "#                                                      reward_series_full_list = reward_series_full_list, \n",
    "#                                                      acting_entity = actor)\n",
    "\n",
    "# this one will include how much damage is being dealt\n",
    "# if an effective weapon is equipped\n",
    "# how many coins are picked up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing a round of combat that includes the queue of actions and possible reactions other entities take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what needs to happen before I can be running combat?\n",
    "# - the function to process a creature's turn needs to be done\n",
    "# - the function to process everyone else's reaction needs to be operational\n",
    "# - enemies need to be able to take their turn, currently they operate as a form of static entity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what needs to happen before the next stage?\n",
    "# - combat situations needs to be randomly generated\n",
    "# - combat scenarios need to be ran millions of times"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
