{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFS running combat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series refers to the sequence of subactions and relevant details needed by the process_turn function.\n",
    "\n",
    "A full_list refers to the collection of series options an actor has to pick from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DFS_World_States import world, world_grid_states, Weapon, Potion, Shield, Wand\n",
    "from DFS_Universal_Rules import theoretical_turn_length, subaction_dict, target_distance_scores, fire_bolt, ray_of_frost, shield\n",
    "from DFS_Action_Series import RuleBasedSequenceDFS, action_rules \n",
    "from DFS_Location_Series import RuleBasedLocationSequenceDFS2, location_rules\n",
    "from DFS_Functions import precalc_reward_series, analyze_reward_distribution, post_loc_series_reward_calc, post_obj_reward_series_calc, post_obj_reward_series_calc2, analyze_reward_distribution_series, calc_new_reward\n",
    "from DFS_Object_Series import RuleBasedObjectSequenceDFS1, object_rules\n",
    "from DFS_Entity_Series import RuleBasedEntitySequenceDFS, entity_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DFS_Entities import entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = world(11)\n",
    "\n",
    "stage.generate_map()\n",
    "\n",
    "actor = entity('player character',stage,'medium')\n",
    "stage.add_entity([0,0],actor)\n",
    "\n",
    "actor.add_spell(fire_bolt)\n",
    "actor.add_spell(ray_of_frost)\n",
    "actor.add_spell(shield)\n",
    "\n",
    "stage.add_item_to_inventory(actor, Weapon('dagger1', 'weapon', 1, 1, 0))\n",
    "stage.add_item_to_inventory(actor, Weapon('dagger2', 'weapon', 1, 1, 0))\n",
    "stage.add_item_to_inventory(actor, Weapon('greataxe', 'weapon', 1, 1, 0))\n",
    "stage.add_item_to_inventory(actor, Shield('shield','shield', 1))\n",
    "stage.add_item_to_inventory(actor, Wand('wand','wand', 1))\n",
    "\n",
    "\n",
    "\n",
    "monster_one = entity('monster',stage,'small','goblin','1x1',False,6)\n",
    "stage.add_entity([2,2],monster_one)\n",
    "\n",
    "monster_two = entity('monster',stage,'medium','guard','1x1',False,6)\n",
    "stage.add_entity([1,1],monster_two)\n",
    "\n",
    "monster_three = entity('monster',stage,'large','horse','2x2',True,12)\n",
    "stage.add_entity([0,-3],monster_three)\n",
    "\n",
    "\n",
    "#stage.add_enemy((-2,0))\n",
    "#stage.add_enemy((0,3))\n",
    "#stage.add_enemy((2,2))\n",
    "#stage.add_enemy((-3,-3))\n",
    "#stage.add_enemy((1,-1))\n",
    "\n",
    "stage.add_coin((3,0))\n",
    "stage.add_coin((-1,-1))\n",
    "stage.add_coin((1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stage.add_weapon_dagger((-2,-1))\n",
    "stage.add_weapon_dagger((-1,-2))\n",
    "stage.add_weapon_greataxe((2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage.grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I should display a visual here of the grid and where each entity and object is located\n",
    "\n",
    "# stage.grid2 is a inhomogeneous list of lists of lists, ints, and strings that represent the grid\n",
    "\n",
    "# I only want to see the entities and objects, so I will create a new list of lists that only contains the entities and objects\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_sequence_generator = RuleBasedSequenceDFS(min_length=0,max_length=theoretical_turn_length, start=0, end=len(subaction_dict), rules=action_rules, acting_entity=actor)\n",
    "action_series_full_list = action_sequence_generator.generate_sequences()\n",
    "#action_series_full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_series_full_list = precalc_reward_series(action_series_full_list, actor)\n",
    "#reward_series_full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 2050851\n",
      "High: 8\n",
      "Low: -2\n",
      "\n",
      "Reward Distribution:\n",
      "% of -2s: 0.06%\n",
      "% of -1s: 1.03%\n",
      "% of 0s: 5.96%\n",
      "% of 1s: 15.88%\n",
      "% of 2s: 31.54%\n",
      "% of 3s: 29.10%\n",
      "% of 4s: 11.68%\n",
      "% of 5s: 3.81%\n",
      "% of 6s: 0.86%\n",
      "% of 7s: 0.08%\n",
      "% of 8s: 0.00%\n",
      "\n",
      "Quality Threshold (99): 5.0\n",
      "Total Qualifiers: 97316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#analyze_reward_distribution(reward_series_full_list, action_series_full_list)\n",
    "action_reward_series_full_list = [[action_series_full_list[i], reward_series_full_list[i]] for i in range(len(action_series_full_list))]\n",
    "\n",
    "analyze_reward_distribution_series(action_reward_series_full_list, actor, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality threshold: 5.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m location_series_generator \u001b[38;5;241m=\u001b[39m RuleBasedLocationSequenceDFS2(action_series_list\u001b[38;5;241m=\u001b[39maction_series_full_list,\n\u001b[0;32m      2\u001b[0m                                                              reward_series_list\u001b[38;5;241m=\u001b[39mreward_series_full_list,\n\u001b[0;32m      3\u001b[0m                                                              location_rules\u001b[38;5;241m=\u001b[39mlocation_rules,\n\u001b[0;32m      4\u001b[0m                                                              acting_entity\u001b[38;5;241m=\u001b[39mactor,\n\u001b[0;32m      5\u001b[0m                                                              target_distance_scores\u001b[38;5;241m=\u001b[39mtarget_distance_scores)\n\u001b[1;32m----> 6\u001b[0m location_series_full_list \u001b[38;5;241m=\u001b[39m \u001b[43mlocation_series_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maxhi\\OneDrive\\Documents\\GitHub\\5e-Simulation\\DFS_Location_Series.py:117\u001b[0m, in \u001b[0;36mRuleBasedLocationSequenceDFS2.generate_sequences\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action_series_index, action_series \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_series_list):\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_series_list[action_series_index] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m quality_threshold:\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;66;03m#print('')\u001b[39;00m\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;66;03m#print('---------------------')\u001b[39;00m\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;66;03m#print(f'{action_series}: {self.reward_series_list[action_series_index]}')\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdfs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43maction_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcurrent_sequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrid_locations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_locations\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_series_list\u001b[38;5;241m.\u001b[39mappend(sequences)\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \n",
      "File \u001b[1;32mc:\\Users\\maxhi\\OneDrive\\Documents\\GitHub\\5e-Simulation\\DFS_Location_Series.py:84\u001b[0m, in \u001b[0;36mRuleBasedLocationSequenceDFS2.dfs\u001b[1;34m(self, action_series, current_sequence, grid_locations)\u001b[0m\n\u001b[0;32m     81\u001b[0m all_sequences \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     82\u001b[0m sub_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(current_sequence)  \u001b[38;5;66;03m# This ensures we're looking at the correct subaction\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m locations_accessible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_potential_locations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtar_act_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtar_act_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_sequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_sequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43macting_entity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macting_entity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid_locations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_locations\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m next_loc \u001b[38;5;129;01min\u001b[39;00m locations_accessible:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_rules(current_sequence, next_loc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macting_entity, tar_act_series):\n",
      "File \u001b[1;32mc:\\Users\\maxhi\\OneDrive\\Documents\\GitHub\\5e-Simulation\\DFS_Location_Series.py:57\u001b[0m, in \u001b[0;36mRuleBasedLocationSequenceDFS2.get_potential_locations\u001b[1;34m(self, sub_index, tar_act_series, current_sequence, acting_entity, grid_locations)\u001b[0m\n\u001b[0;32m     52\u001b[0m locations_accessible \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m grid_locations:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m#if chebyshev_distance(entity_location, loc) <= distance_allowable:\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m#    locations_accessible.append(loc)\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchebyshev_distance_entities\u001b[49m\u001b[43m(\u001b[49m\u001b[43macting_entity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m distance_allowable:\n\u001b[0;32m     58\u001b[0m         locations_accessible\u001b[38;5;241m.\u001b[39mappend(loc)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#print(f'locations accessible {locations_accessible}')\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#print(f'entity is at {entity_location}; allowable distance for action {subaction} is {distance_allowable}; locations accessible are {locations_accessible}')\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m#print(f'Locations accessible: {locations_accessible}')\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#print(' ')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maxhi\\OneDrive\\Documents\\GitHub\\5e-Simulation\\DFS_Functions.py:25\u001b[0m, in \u001b[0;36mchebyshev_distance_entities\u001b[1;34m(entity1, pos2)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchebyshev_distance_entities\u001b[39m(entity1, pos2):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# because the entity's location is stored as a list, due to a large entity taking up multiple spaces\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# the list of location's occupied needs to be checked for the closest space to the target\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# and from there to the target is the distance\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mchebyshev_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpos2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentity1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(distances)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "location_series_generator = RuleBasedLocationSequenceDFS2(action_series_list=action_series_full_list,\n",
    "                                                             reward_series_list=reward_series_full_list,\n",
    "                                                             location_rules=location_rules,\n",
    "                                                             acting_entity=actor,\n",
    "                                                             target_distance_scores=target_distance_scores)\n",
    "location_series_full_list = location_series_generator.generate_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_location_reward_list = post_loc_series_reward_calc(action_series_full_list, location_series_full_list, reward_series_full_list, actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_reward_distribution_series(post_location_reward_list, actor, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Series\n",
    "object_series_generator = RuleBasedObjectSequenceDFS1(post_location_reward_list = post_location_reward_list, \n",
    "                                                     target_distance_scores = target_distance_scores,\n",
    "                                                     object_rules = object_rules, \n",
    "                                                     acting_entity = actor)\n",
    "object_series_full_list = object_series_generator.generate_object_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_object_reward_list = post_obj_reward_series_calc2(object_series_full_list, actor)\n",
    "post_object_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_reward_distribution_series(post_object_reward_list, actor, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity series\n",
    "# in order to specify which entity is being targeted\n",
    "\n",
    "# shortcuts:\n",
    "# - currently based on the location series, if there is only one entity in a space, the entity is automatically targeted\n",
    "# - only if there are multiple entities in a space, the entity series is used to determine the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_series_generator = RuleBasedEntitySequenceDFS(action_location_object_reward_series_full_list = post_object_reward_list,\n",
    "                                                     target_distance_scores = target_distance_scores,\n",
    "                                                     entity_rules = entity_rules,\n",
    "                                                     acting_entity = actor)\n",
    "entity_series_generator.generate_entity_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_location_object_entity_reward_series_full_list = entity_series_generator.generate_entity_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_location_object_entity_reward_series_full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_location_object_entity_reward_series_full_list = calc_new_reward(action_location_object_entity_reward_series_full_list, actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_reward_distribution_series(action_location_object_entity_reward_series_full_list, actor, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post_object_reward_list = post_obj_reward_series_calc(action_series_full_list = action_series_full_list, \n",
    "#                                                      location_series_full_list = location_series_full_list, \n",
    "#                                                      object_series_full_list = object_series_full_list, \n",
    "#                                                      reward_series_full_list = reward_series_full_list, \n",
    "#                                                      acting_entity = actor)\n",
    "\n",
    "# this one will include how much damage is being dealt\n",
    "# if an effective weapon is equipped\n",
    "# how many coins are picked up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing a round of combat that includes the queue of actions and possible reactions other entities take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what needs to happen before I can be running combat?\n",
    "# - the function to process a creature's turn needs to be done\n",
    "# - the function to process everyone else's reaction needs to be operational\n",
    "# - enemies need to be able to take their turn, currently they operate as a form of static entity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what needs to happen before the next stage?\n",
    "# - combat situations needs to be randomly generated\n",
    "# - combat scenarios need to be ran millions of times"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
