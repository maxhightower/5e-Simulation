{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using t-stages instead of a time series dataframe to track combat for reinforcement learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character_Creator - Random Character Function - Class Choice:  <module 'Artificer' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Artificer.py'>\n",
      "Create Character Function - Class: <module 'Artificer' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Artificer.py'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mDice_Rolls\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mEstablishing_Hierarchy\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mCHARACTER_CREATOR\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mMonsters\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mCharacter_Actions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maxhi\\OneDrive\\Documents\\GitHub\\5e-Simulation\\CHARACTER_CREATOR.py:484\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Create_Character(name,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStandard Array\u001b[39m\u001b[38;5;124m'\u001b[39m,species,sub_species,class_choice,background,level)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# test the Random_Character function\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m \u001b[43mRandom_Character\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maxhi\\OneDrive\\Documents\\GitHub\\5e-Simulation\\CHARACTER_CREATOR.py:480\u001b[0m, in \u001b[0;36mRandom_Character\u001b[1;34m()\u001b[0m\n\u001b[0;32m    476\u001b[0m level \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;66;03m#print('Generated ',name)\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m#print('Class: ',class_choice)\u001b[39;00m\n\u001b[1;32m--> 480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCreate_Character\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStandard Array\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mspecies\u001b[49m\u001b[43m,\u001b[49m\u001b[43msub_species\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_choice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maxhi\\OneDrive\\Documents\\GitHub\\5e-Simulation\\CHARACTER_CREATOR.py:255\u001b[0m, in \u001b[0;36mCreate_Character\u001b[1;34m(character_name, Score_Generation_Method, Species, Subspecies, Class, Background, Level)\u001b[0m\n\u001b[0;32m    252\u001b[0m character_name\u001b[38;5;241m.\u001b[39mCurrent_HP \u001b[38;5;241m=\u001b[39m character_name\u001b[38;5;241m.\u001b[39mHP\n\u001b[0;32m    254\u001b[0m character_name\u001b[38;5;241m.\u001b[39mActions \u001b[38;5;241m=\u001b[39m character_name\u001b[38;5;241m.\u001b[39mActions\u001b[38;5;241m.\u001b[39mappend(Armor_and_Weapons\u001b[38;5;241m.\u001b[39mDon_Armor(Armor_and_Weapons\u001b[38;5;241m.\u001b[39mShield,character_name))\n\u001b[1;32m--> 255\u001b[0m character_name\u001b[38;5;241m.\u001b[39mActions \u001b[38;5;241m=\u001b[39m \u001b[43mcharacter_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mActions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(Armor_and_Weapons\u001b[38;5;241m.\u001b[39mDoff_Armor(Armor_and_Weapons\u001b[38;5;241m.\u001b[39mShield,character_name))\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m#Name.Bonus_Actions[]\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m#Name.Reactions[]\u001b[39;00m\n\u001b[0;32m    259\u001b[0m character_name\u001b[38;5;241m.\u001b[39mOne_Minute_Options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnlimited\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import Species\n",
    "import Backgrounds\n",
    "import Armor_and_Weapons\n",
    "import Dice_Rolls\n",
    "import Establishing_Hierarchy\n",
    "import CHARACTER_CREATOR\n",
    "import Monsters\n",
    "import Character_Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_situation(character_num):\n",
    "    print('generating situation...')\n",
    "\n",
    "    # for the number of characters, randomly generate a Player_Character using Random_Character()\n",
    "    entities = []\n",
    "    print('generating characters...')\n",
    "    for i in range(character_num):\n",
    "        entities.append(CHARACTER_CREATOR.Random_Character())\n",
    "\n",
    "    # for the number of entities, within each entity's flesh out the Active_Conditions and Circumstances dictionaries\n",
    "    for entity in range(len(entities)):\n",
    "        other_entities = entities.copy()\n",
    "        other_entities.pop(entity)\n",
    "        \n",
    "        self_name = str(entities[entity].Name)\n",
    "        entities[entity].Circumstances['Attack Rolls'][self_name] = None\n",
    "        # I want to add a key for each other entity in the Active_Conditions dictionaries\n",
    "        for other_entity in range(len(other_entities)):\n",
    "            entities[entity].Active_Conditions[str(entities[other_entity])] = []\n",
    "            other_entity_name = str(other_entities[other_entity].Name)\n",
    "            entities[entity].Circumstances['Attack Rolls'][other_entity_name] = None\n",
    "\n",
    "            #entities[entity].Circumstances['Attack Rolls'][entity_name] = 'placeholder'\n",
    "            #print(entities[other_entity].Name)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_combat(character_num):\n",
    "    print('generating characters...')\n",
    "    combat_situation = generate_situation(character_num)\n",
    "    \n",
    "\n",
    "    print('adding actions to characters...')\n",
    "    for entity in range(len(combat_situation)):\n",
    "        combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.No_Action(combat_situation[entity],combat_situation,combat_log_new))\n",
    "        combat_situation[entity].Bonus_Actions = combat_situation[entity].Bonus_Actions.append(Character_Actions.No_Bonus_Action(combat_situation[entity],combat_situation,combat_log_new))\n",
    "        combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.Attack_Action(combat_situation[entity],combat_situation,combat_log_new))\n",
    "        combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.Dodge_Action(combat_situation[entity],combat_situation,combat_log_new))\n",
    "        combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.Help_Action(combat_situation[entity],combat_situation,combat_log_new))\n",
    "        combat_situation[entity].Free_Actions = combat_situation[entity].Free_Actions.append(Character_Actions.Move(combat_situation[entity],combat_situation,combat_log_new))\n",
    "        Character_Actions.Equip_Weapon(combat_situation[entity],Character_Actions.Choose_Random_Weapon(combat_situation[entity]))\n",
    "\n",
    "        # assign a unique location to each entity within a 12x12 grid\n",
    "        combat_situation[entity].Location['X'] = np.random.randint(0,12)\n",
    "        combat_situation[entity].Location['Y'] = np.random.randint(0,12)\n",
    "\n",
    "    print('building environment...')\n",
    "    class CombatEnv(Env):\n",
    "        def __init__(self):\n",
    "            # the action space needs to combine Action, Bonus Action, and Movement\n",
    "            # so the action space might need to be a dictionary with keys \"Action\", \"Bonus Action\", and \"Movement\"\n",
    "            # and the values will be the actions that can be taken\n",
    "\n",
    "\n",
    "            # I need to generate creatures first and foremost\n",
    "            # and then for each action they are capable of, assign action spaces\n",
    "\n",
    "            # action_space_dict = Dict({\n",
    "            #    \"Action\": Discrete(4),\n",
    "            #    'Action Order': Discrete(3), # 3 = Action goes last, 2 = Action goes second, 1 = Action goes first\n",
    "            #    \"Bonus Action\": Discrete(4),\n",
    "            #    'Bonus Action Order': Discrete(3), # 3 = Bonus Action goes last, 2 = Bonus Action goes second, 1 = Bonus Action goes first\n",
    "            #    \"Movement\": Discrete(4), # how tf am I going to implement split movement\n",
    "            #})\n",
    "            # and then a function to convert it into something usable\n",
    "\n",
    "            #for character in combat_situation:\n",
    "            #    character_action_space = spaces.Discrete(len(character.actions))\n",
    "\n",
    "            for character in combat_situation:\n",
    "                action_space_name = str(combat_situation[character].Name) + '_action_space'\n",
    "                action_space_name = spaces.Discrete(len(combat_situation[character].Actions))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def take_turn(combat_log_new,character):\n",
    "        # the take_turns function needs to be overhauled so that it's attaching only one row at a time to the combat_log_new dataframe\n",
    "        # that means that it needs to choose Action, Bonus_Action, or Movement, then enact it, then concat it to the combat_log_new dataframe before continuing with the rest\n",
    "        # that new last row will be the basis for the next action\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # need to decide which action_type to take first: Actions or Bonus_Actions\n",
    "        action_types = ['Actions','Bonus_Actions','Movement']\n",
    "            # Move Splitting\n",
    "            # Free Action\n",
    "            # Object Interaction\n",
    "        \n",
    "\n",
    "    \n",
    "    # making a round 0 to represent the spawning conditions\n",
    "    first_row = pd.DataFrame({'Combat Round':0,\n",
    "                                                              'Action Time': None,\n",
    "                                                              'Action Name': None, \n",
    "                                                              'Action Type': None,\n",
    "                                                              'Target': None,\n",
    "                                                              'Action Result': None,\n",
    "                                                              'Current Allied Ability Check':'Spawning','Current Allied Attack Roll':'Spawning','Current Allied Saving Throw':'Spawning','Current Allied Damage Roll':'Spawning','Current Enemy Ability Check':'Spawning','Current Enemy Attack Roll':'Spawning','Current Enemy Saving Throw':'Spawning','Current Enemy Damage Roll':'Spawning'}, index=[0])\n",
    "\n",
    "    for entity in range(len(combat_situation)):\n",
    "        first_row[combat_situation[entity].Name + ' Acting True'] = 0\n",
    "        first_row[combat_situation[entity].Name + ' Current_HP'] = combat_situation[entity].HP\n",
    "        first_row[combat_situation[entity].Name + ' Temp_HP'] = combat_situation[entity].Temp_HP\n",
    "        first_row[combat_situation[entity].Name + ' Size'] = combat_situation[entity].Size\n",
    "        first_row[combat_situation[entity].Name + ' Walking Speed'] = combat_situation[entity].Speed['Walking']\n",
    "        first_row[combat_situation[entity].Name + ' Flying Speed'] = combat_situation[entity].Speed['Flying']\n",
    "        first_row[combat_situation[entity].Name + ' Str_Score'] = combat_situation[entity].Str_Score\n",
    "        first_row[combat_situation[entity].Name + ' Dex_Score'] = combat_situation[entity].Dex_Score\n",
    "        first_row[combat_situation[entity].Name + ' Con_Score'] = combat_situation[entity].Con_Score\n",
    "        first_row[combat_situation[entity].Name + ' Int_Score'] = combat_situation[entity].Int_Score\n",
    "        first_row[combat_situation[entity].Name + ' Wis_Score'] = combat_situation[entity].Wis_Score\n",
    "        first_row[combat_situation[entity].Name + ' Cha_Score'] = combat_situation[entity].Cha_Score\n",
    "        first_row[combat_situation[entity].Name + ' Active_Conditions'] = combat_situation[entity].Active_Conditions\n",
    "        first_row[combat_situation[entity].Name + ' Concentrating'] = combat_situation[entity].Concentrating\n",
    "        first_row[combat_situation[entity].Name + 'Location X'] = combat_situation[entity].Location['X']\n",
    "        first_row[combat_situation[entity].Name + 'Location Y'] = combat_situation[entity].Location['Y']\n",
    "        first_row[combat_situation[entity].Name + 'Location Z'] = combat_situation[entity].Location['Z']\n",
    "\n",
    "    # attach the new_round dictionary to the combat_log_new dataframe using concat\n",
    "    combat_log_new = pd.concat([combat_log_new,pd.DataFrame(first_row)],ignore_index=False)\n",
    "\n",
    "    for character in range(len(combat_situation)):\n",
    "        # print their starting health\n",
    "        print('Character: ' + combat_situation[character].Name + ' has ' + str(combat_situation[character].Current_HP) + ' HP')\n",
    "\n",
    "    print('taking turns...')\n",
    "    for Combat_Round in range(1,3):\n",
    "        combat_round += 1\n",
    "\n",
    "        for entity in range(len(combat_situation)):\n",
    "            combat_log_new = pd.concat([combat_log_new,take_turn(combat_log_new,entity)], ignore_index=True, axis=0)\n",
    "\n",
    "\n",
    "    combat_log_new = combat_log_new.reindex(columns=['Combat Round'] + list(combat_log_new.columns[1:][combat_log_new.columns[1:].str.contains('Acting True')]) + list(combat_log_new.columns[1:][combat_log_new.columns[1:].str.contains('Current_HP')]) + list(combat_log_new.columns[1:][~combat_log_new.columns[1:].str.contains('Acting True') & ~combat_log_new.columns[1:].str.contains('Current_HP')]))\n",
    "    \n",
    "    return CombatEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass CombatEnv(Env):\\n    def __init__(self):\\n        # the action space needs to combine Action, Bonus Action, and Movement\\n        # so the action space might need to be a dictionary with keys \"Action\", \"Bonus Action\", and \"Movement\"\\n        # and the values will be the actions that can be taken\\n\\n\\n        # I need to generate creatures first and foremost\\n        # and then for each action they are capable of, assign action spaces\\n\\n        # action_space_dict = Dict({\\n        #    \"Action\": Discrete(4),\\n        #    \\'Action Order\\': Discrete(3), # 3 = Action goes last, 2 = Action goes second, 1 = Action goes first\\n        #    \"Bonus Action\": Discrete(4),\\n        #    \\'Bonus Action Order\\': Discrete(3), # 3 = Bonus Action goes last, 2 = Bonus Action goes second, 1 = Bonus Action goes first\\n        #    \"Movement\": Discrete(4), # how tf am I going to implement split movement\\n        #})\\n        # and then a function to convert it into something usable\\n\\n        #for character in combat_situation:\\n        #    character_action_space = spaces.Discrete(len(character.actions))\\n\\n\\n\\n        # the combat array\\n        self.observation_space = Box(low=0, high=100, shape=(3,))\\n        \\n        ######## creating a state\\n        # what needs to be represented here?\\n        # for each creature in environment: Maximum_HP, Current_HP, Temp_HP, AC, Size, Position, Speed, Strength, Dexterity, Constitution, Intelligence, Wisdom, Charisma, Active Conditions, Concentrating,  \\n\\n        self.state = [100, 100, 100] # placeholder for now\\n        \\n        # set episode length\\n        self.max_turns = 10\\n\\n    def step(self, action):\\n        # apply actions\\n        self.state += action\\n        if self.state[0] > 100:\\n            reward = 1\\n        else:\\n            reward = 0\\n            \\n        if placeholder <= 0:\\n            done = True\\n        else:\\n            done = False\\n        info = {}\\n        return self.state, reward, done, info\\n        \\n    def render(self):\\n        pass\\n\\n    def reset(self):\\n        self.state = [100, 100, 100]\\n        return self.state\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class CombatEnv(Env):\n",
    "    def __init__(self):\n",
    "        # the action space needs to combine Action, Bonus Action, and Movement\n",
    "        # so the action space might need to be a dictionary with keys \"Action\", \"Bonus Action\", and \"Movement\"\n",
    "        # and the values will be the actions that can be taken\n",
    "\n",
    "\n",
    "        # I need to generate creatures first and foremost\n",
    "        # and then for each action they are capable of, assign action spaces\n",
    "\n",
    "        # action_space_dict = Dict({\n",
    "        #    \"Action\": Discrete(4),\n",
    "        #    'Action Order': Discrete(3), # 3 = Action goes last, 2 = Action goes second, 1 = Action goes first\n",
    "        #    \"Bonus Action\": Discrete(4),\n",
    "        #    'Bonus Action Order': Discrete(3), # 3 = Bonus Action goes last, 2 = Bonus Action goes second, 1 = Bonus Action goes first\n",
    "        #    \"Movement\": Discrete(4), # how tf am I going to implement split movement\n",
    "        #})\n",
    "        # and then a function to convert it into something usable\n",
    "\n",
    "        #for character in combat_situation:\n",
    "        #    character_action_space = spaces.Discrete(len(character.actions))\n",
    "\n",
    "\n",
    "\n",
    "        # the combat array\n",
    "        self.observation_space = Box(low=0, high=100, shape=(3,))\n",
    "        \n",
    "        ######## creating a state\n",
    "        # what needs to be represented here?\n",
    "        # for each creature in environment: Maximum_HP, Current_HP, Temp_HP, AC, Size, Position, Speed, Strength, Dexterity, Constitution, Intelligence, Wisdom, Charisma, Active Conditions, Concentrating,  \n",
    "\n",
    "        self.state = [100, 100, 100] # placeholder for now\n",
    "        \n",
    "        # set episode length\n",
    "        self.max_turns = 10\n",
    "\n",
    "    def step(self, action):\n",
    "        # apply actions\n",
    "        self.state += action\n",
    "        if self.state[0] > 100:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "            \n",
    "        if placeholder <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        info = {}\n",
    "        return self.state, reward, done, info\n",
    "        \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = [100, 100, 100]\n",
    "        return self.state\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating characters...\n",
      "generating situation...\n",
      "generating characters...\n",
      "Character_Creator - Random Character Function - Class Choice:  <module 'Bard' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Bard.py'>\n",
      "Create Character Function - Class: <module 'Bard' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Bard.py'>\n",
      "Character_Creator - Random Character Function - Class Choice:  <module 'Artificer' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Artificer.py'>\n",
      "Create Character Function - Class: <module 'Artificer' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Artificer.py'>\n",
      "Character_Creator - Random Character Function - Class Choice:  <module 'Barbarian' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Barbarian.py'>\n",
      "Create Character Function - Class: <module 'Barbarian' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Barbarian.py'>\n",
      "Character_Creator - Random Character Function - Class Choice:  <module 'Bard' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Bard.py'>\n",
      "Create Character Function - Class: <module 'Bard' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Bard.py'>\n",
      "adding actions to characters...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_combat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m states \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m actions \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn\n",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m, in \u001b[0;36mgenerate_combat\u001b[1;34m(character_num)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madding actions to characters...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(combat_situation)):\n\u001b[1;32m----> 8\u001b[0m     combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions \u001b[38;5;241m=\u001b[39m \u001b[43mcombat_situation\u001b[49m\u001b[43m[\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mActions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(Character_Actions\u001b[38;5;241m.\u001b[39mNo_Action(combat_situation[entity],combat_situation,combat_log_new))\n\u001b[0;32m      9\u001b[0m     combat_situation[entity]\u001b[38;5;241m.\u001b[39mBonus_Actions \u001b[38;5;241m=\u001b[39m combat_situation[entity]\u001b[38;5;241m.\u001b[39mBonus_Actions\u001b[38;5;241m.\u001b[39mappend(Character_Actions\u001b[38;5;241m.\u001b[39mNo_Bonus_Action(combat_situation[entity],combat_situation,combat_log_new))\n\u001b[0;32m     10\u001b[0m     combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions \u001b[38;5;241m=\u001b[39m combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions\u001b[38;5;241m.\u001b[39mappend(Character_Actions\u001b[38;5;241m.\u001b[39mAttack_Action(combat_situation[entity],combat_situation,combat_log_new))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "env = generate_combat(4)\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m      9\u001b[0m     action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m---> 10\u001b[0m     n_state, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Score:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(episode, score))\n",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m, in \u001b[0;36mCombatEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# apply actions\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m:\n\u001b[0;32m     18\u001b[0m         reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m states \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      2\u001b[0m actions \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, activation='relu', input_shape=states))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
