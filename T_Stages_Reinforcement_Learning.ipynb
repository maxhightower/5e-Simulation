{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using t-stages instead of a time series dataframe to track combat for reinforcement learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Species\n",
    "import Backgrounds\n",
    "import Armor_and_Weapons\n",
    "import Dice_Rolls\n",
    "import Establishing_Hierarchy\n",
    "import CHARACTER_CREATOR\n",
    "import Monsters\n",
    "import Character_Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_situation(character_num):\n",
    "    print('generating situation...')\n",
    "\n",
    "    # for the number of characters, randomly generate a Player_Character using Random_Character()\n",
    "    entities = []\n",
    "    print('generating characters...')\n",
    "    for i in range(character_num):\n",
    "        entities.append(CHARACTER_CREATOR.Random_Character())\n",
    "\n",
    "    # for the number of entities, within each entity's flesh out the Active_Conditions and Circumstances dictionaries\n",
    "    for entity in range(len(entities)):\n",
    "        other_entities = entities.copy()\n",
    "        other_entities.pop(entity)\n",
    "        \n",
    "        self_name = str(entities[entity].Name)\n",
    "        entities[entity].Circumstances['Attack Rolls'][self_name] = None\n",
    "        # I want to add a key for each other entity in the Active_Conditions dictionaries\n",
    "        for other_entity in range(len(other_entities)):\n",
    "            entities[entity].Active_Conditions[str(entities[other_entity])] = []\n",
    "            other_entity_name = str(other_entities[other_entity].Name)\n",
    "            entities[entity].Circumstances['Attack Rolls'][other_entity_name] = None\n",
    "\n",
    "            #entities[entity].Circumstances['Attack Rolls'][entity_name] = 'placeholder'\n",
    "            #print(entities[other_entity].Name)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_combat(character_num):\n",
    "    print('generating characters...')\n",
    "    combat_situation = generate_situation(character_num)\n",
    "    \n",
    "\n",
    "    print('adding actions to characters...')\n",
    "    for entity in range(len(combat_situation)):\n",
    "    #    combat_situation[entity].Actions = [Character_Actions.No_Action(combat_situation[entity],combat_situation)]\n",
    "    #    combat_situation[entity].Bonus_Actions = combat_situation[entity].Bonus_Actions.append(Character_Actions.No_Bonus_Action(combat_situation[entity],combat_situation,))\n",
    "    #    combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.Attack_Action(combat_situation[entity],combat_situation))\n",
    "    #    combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.Dodge_Action(combat_situation[entity],combat_situation))\n",
    "    #    combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.Help_Action(combat_situation[entity],combat_situation))\n",
    "    #    combat_situation[entity].Free_Actions = combat_situation[entity].Free_Actions.append(Character_Actions.Move(combat_situation[entity],combat_situation))\n",
    "    #    Character_Actions.Equip_Weapon(combat_situation[entity],Character_Actions.Choose_Random_Weapon(combat_situation[entity]))\n",
    "\n",
    "        # assign a unique location to each entity within a 12x12 grid\n",
    "        combat_situation[entity].Location['X'] = np.random.randint(0,12)\n",
    "        combat_situation[entity].Location['Y'] = np.random.randint(0,12)\n",
    "        combat_situation[entity].Location['Z'] = 0\n",
    "\n",
    "    print('building environment...')\n",
    "    class CombatEnv(Env):\n",
    "        def __init__(self):\n",
    "            # the action space needs to combine Action, Bonus Action, and Movement\n",
    "            # so the action space might need to be a dictionary with keys \"Action\", \"Bonus Action\", and \"Movement\"\n",
    "            # and the values will be the actions that can be taken\n",
    "\n",
    "\n",
    "            # I need to generate creatures first and foremost\n",
    "            # and then for each action they are capable of, assign action spaces\n",
    "\n",
    "            # action_space_dict = Dict({\n",
    "            #    \"Action\": Discrete(4),\n",
    "            #    'Action Order': Discrete(3), # 3 = Action goes last, 2 = Action goes second, 1 = Action goes first\n",
    "            #    \"Bonus Action\": Discrete(4),\n",
    "            #    'Bonus Action Order': Discrete(3), # 3 = Bonus Action goes last, 2 = Bonus Action goes second, 1 = Bonus Action goes first\n",
    "            #    \"Movement\": Discrete(4), # how tf am I going to implement split movement\n",
    "            #})\n",
    "            # and then a function to convert it into something usable\n",
    "\n",
    "            #for character in combat_situation:\n",
    "            #    character_action_space = spaces.Discrete(len(character.actions))\n",
    "\n",
    "\n",
    "            ##### State Array\n",
    "            state_array = []\n",
    "            for character in combat_situation:\n",
    "                state_array.append(character.Name + ' Current_HP')\n",
    "                state_array.append(character.Name + ' Temp_HP')\n",
    "                state_array.append(character.Name + ' Size')\n",
    "                state_array.append(character.Name + ' Walking Speed')\n",
    "                state_array.append(character.Name + ' Flying Speed')\n",
    "                state_array.append(character.Name + ' Str_Score')\n",
    "                state_array.append(character.Name + ' Dex_Score')\n",
    "                state_array.append(character.Name + ' Con_Score')\n",
    "                state_array.append(character.Name + ' Int_Score')\n",
    "                state_array.append(character.Name + ' Wis_Score')\n",
    "                state_array.append(character.Name + ' Cha_Score')\n",
    "                state_array.append(character.Name + ' Active_Conditions')\n",
    "                state_array.append(character.Name + ' Concentrating')\n",
    "                state_array.append(character.Name + 'Location X')\n",
    "                state_array.append(character.Name + 'Location Y')\n",
    "                state_array.append(character.Name + 'Location Z')\n",
    "            \n",
    "            self.state = np.array(state_array)\n",
    "\n",
    "            for entity in range(len(combat_situation)):\n",
    "                combat_situation[entity].Bonus_Actions = []\n",
    "                combat_situation[entity].Bonus_Actions = combat_situation[entity].Bonus_Actions.append(Character_Actions.No_Bonus_Action(combat_situation[entity],combat_situation,self.state))\n",
    "                \n",
    "                \n",
    "                print(combat_situation[entity])\n",
    "                print(combat_situation[entity].Actions)\n",
    "                combat_situation[entity].Actions = []\n",
    "                print(Character_Actions.No_Action(combat_situation[entity],combat_situation,self.state))\n",
    "                combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.No_Action(combat_situation[entity],combat_situation,self.state))\n",
    "                print(combat_situation[entity].Actions)\n",
    "\n",
    "                combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.Attack_Action(combat_situation[entity],combat_situation,self.state))\n",
    "                combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.Dodge_Action(combat_situation[entity],combat_situation,self.state))\n",
    "                combat_situation[entity].Actions = combat_situation[entity].Actions.append(Character_Actions.Help_Action(combat_situation[entity],combat_situation,self.state))\n",
    "                combat_situation[entity].Free_Actions = combat_situation[entity].Free_Actions.append(Character_Actions.Move(combat_situation[entity],combat_situation,self.state))\n",
    "                Character_Actions.Equip_Weapon(combat_situation[entity],Character_Actions.Choose_Random_Weapon(combat_situation[entity]))\n",
    "\n",
    "                # assign a unique location to each entity within a 12x12 grid\n",
    "                combat_situation[entity].Location['X'] = np.random.randint(0,12)\n",
    "                combat_situation[entity].Location['Y'] = np.random.randint(0,12)\n",
    "\n",
    "\n",
    "\n",
    "            ###### Observation Space\n",
    "            # do I need an observation space per character?\n",
    "            self.observation_space = Box(low=0, high=1, shape=(len(self.state),), dtype=np.float32)\n",
    "\n",
    "\n",
    "            ###### Action Space\n",
    "            for character in combat_situation:\n",
    "                action_space_name = str(combat_situation[character].Name) + '_action_space'\n",
    "                action_space_name = gym.spaces.Discrete(len(combat_situation[character].Actions))\n",
    "\n",
    "            ###### Other\n",
    "            self.max_turns = 10\n",
    "            \n",
    "        def step(self, action):\n",
    "            pass\n",
    "\n",
    "        def render(self):\n",
    "            pass\n",
    "\n",
    "        def reset(self):\n",
    "            pass\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def take_turn(combat_log_new,character):\n",
    "        # the take_turns function needs to be overhauled so that it's attaching only one row at a time to the combat_log_new dataframe\n",
    "        # that means that it needs to choose Action, Bonus_Action, or Movement, then enact it, then concat it to the combat_log_new dataframe before continuing with the rest\n",
    "        # that new last row will be the basis for the next action\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # need to decide which action_type to take first: Actions or Bonus_Actions\n",
    "        action_types = ['Actions','Bonus_Actions','Movement']\n",
    "            # Move Splitting\n",
    "            # Free Action\n",
    "            # Object Interaction\n",
    "        \n",
    "\n",
    "    \n",
    "    # making a round 0 to represent the spawning conditions\n",
    "    first_row = pd.DataFrame({'Combat Round':0,\n",
    "                                                              'Action Time': None,\n",
    "                                                              'Action Name': None, \n",
    "                                                              'Action Type': None,\n",
    "                                                              'Target': None,\n",
    "                                                              'Action Result': None,\n",
    "                                                              'Current Allied Ability Check':'Spawning','Current Allied Attack Roll':'Spawning','Current Allied Saving Throw':'Spawning','Current Allied Damage Roll':'Spawning','Current Enemy Ability Check':'Spawning','Current Enemy Attack Roll':'Spawning','Current Enemy Saving Throw':'Spawning','Current Enemy Damage Roll':'Spawning'}, index=[0])\n",
    "\n",
    "    for entity in range(len(combat_situation)):\n",
    "        first_row[combat_situation[entity].Name + ' Acting True'] = 0\n",
    "        first_row[combat_situation[entity].Name + ' Current_HP'] = combat_situation[entity].HP\n",
    "        first_row[combat_situation[entity].Name + ' Temp_HP'] = combat_situation[entity].Temp_HP\n",
    "        first_row[combat_situation[entity].Name + ' Size'] = combat_situation[entity].Size\n",
    "        first_row[combat_situation[entity].Name + ' Walking Speed'] = combat_situation[entity].Speed['Walking']\n",
    "        first_row[combat_situation[entity].Name + ' Flying Speed'] = combat_situation[entity].Speed['Flying']\n",
    "        first_row[combat_situation[entity].Name + ' Str_Score'] = combat_situation[entity].Str_Score\n",
    "        first_row[combat_situation[entity].Name + ' Dex_Score'] = combat_situation[entity].Dex_Score\n",
    "        first_row[combat_situation[entity].Name + ' Con_Score'] = combat_situation[entity].Con_Score\n",
    "        first_row[combat_situation[entity].Name + ' Int_Score'] = combat_situation[entity].Int_Score\n",
    "        first_row[combat_situation[entity].Name + ' Wis_Score'] = combat_situation[entity].Wis_Score\n",
    "        first_row[combat_situation[entity].Name + ' Cha_Score'] = combat_situation[entity].Cha_Score\n",
    "        first_row[combat_situation[entity].Name + ' Active_Conditions'] = combat_situation[entity].Active_Conditions\n",
    "        first_row[combat_situation[entity].Name + ' Concentrating'] = combat_situation[entity].Concentrating\n",
    "        first_row[combat_situation[entity].Name + 'Location X'] = combat_situation[entity].Location['X']\n",
    "        first_row[combat_situation[entity].Name + 'Location Y'] = combat_situation[entity].Location['Y']\n",
    "        first_row[combat_situation[entity].Name + 'Location Z'] = combat_situation[entity].Location['Z']\n",
    "\n",
    "    # attach the new_round dictionary to the combat_log_new dataframe using concat\n",
    "    #combat_log_new = pd.concat([combat_log_new,pd.DataFrame(first_row)],ignore_index=False)\n",
    "\n",
    "    #for character in range(len(combat_situation)):\n",
    "        # print their starting health\n",
    "    #    print('Character: ' + combat_situation[character].Name + ' has ' + str(combat_situation[character].Current_HP) + ' HP')\n",
    "\n",
    "    #print('taking turns...')\n",
    "    #for Combat_Round in range(1,3):\n",
    "    #    combat_round += 1\n",
    "\n",
    "    #    for entity in range(len(combat_situation)):\n",
    "    #        combat_log_new = pd.concat([combat_log_new,take_turn(combat_log_new,entity)], ignore_index=True, axis=0)\n",
    "\n",
    "\n",
    "    #combat_log_new = combat_log_new.reindex(columns=['Combat Round'] + list(combat_log_new.columns[1:][combat_log_new.columns[1:].str.contains('Acting True')]) + list(combat_log_new.columns[1:][combat_log_new.columns[1:].str.contains('Current_HP')]) + list(combat_log_new.columns[1:][~combat_log_new.columns[1:].str.contains('Acting True') & ~combat_log_new.columns[1:].str.contains('Current_HP')]))\n",
    "    \n",
    "    return CombatEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass CombatEnv(Env):\\n    def __init__(self):\\n        # the action space needs to combine Action, Bonus Action, and Movement\\n        # so the action space might need to be a dictionary with keys \"Action\", \"Bonus Action\", and \"Movement\"\\n        # and the values will be the actions that can be taken\\n\\n\\n        # I need to generate creatures first and foremost\\n        # and then for each action they are capable of, assign action spaces\\n\\n        # action_space_dict = Dict({\\n        #    \"Action\": Discrete(4),\\n        #    \\'Action Order\\': Discrete(3), # 3 = Action goes last, 2 = Action goes second, 1 = Action goes first\\n        #    \"Bonus Action\": Discrete(4),\\n        #    \\'Bonus Action Order\\': Discrete(3), # 3 = Bonus Action goes last, 2 = Bonus Action goes second, 1 = Bonus Action goes first\\n        #    \"Movement\": Discrete(4), # how tf am I going to implement split movement\\n        #})\\n        # and then a function to convert it into something usable\\n\\n        #for character in combat_situation:\\n        #    character_action_space = spaces.Discrete(len(character.actions))\\n\\n\\n\\n        # the combat array\\n        self.observation_space = Box(low=0, high=100, shape=(3,))\\n        \\n        ######## creating a state\\n        # what needs to be represented here?\\n        # for each creature in environment: Maximum_HP, Current_HP, Temp_HP, AC, Size, Position, Speed, Strength, Dexterity, Constitution, Intelligence, Wisdom, Charisma, Active Conditions, Concentrating,  \\n\\n        self.state = [100, 100, 100] # placeholder for now\\n        \\n        # set episode length\\n        self.max_turns = 10\\n\\n    def step(self, action):\\n        # apply actions\\n        self.state += action\\n        if self.state[0] > 100:\\n            reward = 1\\n        else:\\n            reward = 0\\n            \\n        if placeholder <= 0:\\n            done = True\\n        else:\\n            done = False\\n        info = {}\\n        return self.state, reward, done, info\\n        \\n    def render(self):\\n        pass\\n\\n    def reset(self):\\n        self.state = [100, 100, 100]\\n        return self.state\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class CombatEnv(Env):\n",
    "    def __init__(self):\n",
    "        # the action space needs to combine Action, Bonus Action, and Movement\n",
    "        # so the action space might need to be a dictionary with keys \"Action\", \"Bonus Action\", and \"Movement\"\n",
    "        # and the values will be the actions that can be taken\n",
    "\n",
    "\n",
    "        # I need to generate creatures first and foremost\n",
    "        # and then for each action they are capable of, assign action spaces\n",
    "\n",
    "        # action_space_dict = Dict({\n",
    "        #    \"Action\": Discrete(4),\n",
    "        #    'Action Order': Discrete(3), # 3 = Action goes last, 2 = Action goes second, 1 = Action goes first\n",
    "        #    \"Bonus Action\": Discrete(4),\n",
    "        #    'Bonus Action Order': Discrete(3), # 3 = Bonus Action goes last, 2 = Bonus Action goes second, 1 = Bonus Action goes first\n",
    "        #    \"Movement\": Discrete(4), # how tf am I going to implement split movement\n",
    "        #})\n",
    "        # and then a function to convert it into something usable\n",
    "\n",
    "        #for character in combat_situation:\n",
    "        #    character_action_space = spaces.Discrete(len(character.actions))\n",
    "\n",
    "\n",
    "\n",
    "        # the combat array\n",
    "        self.observation_space = Box(low=0, high=100, shape=(3,))\n",
    "        \n",
    "        ######## creating a state\n",
    "        # what needs to be represented here?\n",
    "        # for each creature in environment: Maximum_HP, Current_HP, Temp_HP, AC, Size, Position, Speed, Strength, Dexterity, Constitution, Intelligence, Wisdom, Charisma, Active Conditions, Concentrating,  \n",
    "\n",
    "        self.state = [100, 100, 100] # placeholder for now\n",
    "        \n",
    "        # set episode length\n",
    "        self.max_turns = 10\n",
    "\n",
    "    def step(self, action):\n",
    "        # apply actions\n",
    "        self.state += action\n",
    "        if self.state[0] > 100:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "            \n",
    "        if placeholder <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        info = {}\n",
    "        return self.state, reward, done, info\n",
    "        \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = [100, 100, 100]\n",
    "        return self.state\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating characters...\n",
      "generating situation...\n",
      "generating characters...\n",
      "Character_Creator - Random Character Function - Class Choice:  <module 'Artificer' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Artificer.py'>\n",
      "Create Character Function - Class: <module 'Artificer' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Artificer.py'>\n",
      "Character_Creator - Random Character Function - Class Choice:  <module 'Bard' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Bard.py'>\n",
      "Create Character Function - Class: <module 'Bard' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Bard.py'>\n",
      "Character_Creator - Random Character Function - Class Choice:  <module 'Barbarian' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Barbarian.py'>\n",
      "Create Character Function - Class: <module 'Barbarian' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Barbarian.py'>\n",
      "Character_Creator - Random Character Function - Class Choice:  <module 'Artificer' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Artificer.py'>\n",
      "Create Character Function - Class: <module 'Artificer' from 'c:\\\\Users\\\\maxhi\\\\OneDrive\\\\Documents\\\\GitHub\\\\5e-Simulation\\\\Artificer.py'>\n",
      "adding actions to characters...\n",
      "building environment...\n",
      "<Establishing_Hierarchy.Player_Character object at 0x000001D7DCC85640>\n",
      "None\n",
      "0\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_combat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m states \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m actions \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn\n",
      "Cell \u001b[1;32mIn[78], line 178\u001b[0m, in \u001b[0;36mgenerate_combat\u001b[1;34m(character_num)\u001b[0m\n\u001b[0;32m    159\u001b[0m     first_row[combat_situation[entity]\u001b[38;5;241m.\u001b[39mName \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation Z\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m combat_situation[entity]\u001b[38;5;241m.\u001b[39mLocation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# attach the new_round dictionary to the combat_log_new dataframe using concat\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m#combat_log_new = pd.concat([combat_log_new,pd.DataFrame(first_row)],ignore_index=False)\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m#combat_log_new = combat_log_new.reindex(columns=['Combat Round'] + list(combat_log_new.columns[1:][combat_log_new.columns[1:].str.contains('Acting True')]) + list(combat_log_new.columns[1:][combat_log_new.columns[1:].str.contains('Current_HP')]) + list(combat_log_new.columns[1:][~combat_log_new.columns[1:].str.contains('Acting True') & ~combat_log_new.columns[1:].str.contains('Current_HP')]))\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCombatEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 79\u001b[0m, in \u001b[0;36mgenerate_combat.<locals>.CombatEnv.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions \u001b[38;5;241m=\u001b[39m combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions\u001b[38;5;241m.\u001b[39mappend(Character_Actions\u001b[38;5;241m.\u001b[39mNo_Action(combat_situation[entity],combat_situation,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate))\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions)\n\u001b[1;32m---> 79\u001b[0m combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions \u001b[38;5;241m=\u001b[39m \u001b[43mcombat_situation\u001b[49m\u001b[43m[\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mActions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(Character_Actions\u001b[38;5;241m.\u001b[39mAttack_Action(combat_situation[entity],combat_situation,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate))\n\u001b[0;32m     80\u001b[0m combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions \u001b[38;5;241m=\u001b[39m combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions\u001b[38;5;241m.\u001b[39mappend(Character_Actions\u001b[38;5;241m.\u001b[39mDodge_Action(combat_situation[entity],combat_situation,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate))\n\u001b[0;32m     81\u001b[0m combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions \u001b[38;5;241m=\u001b[39m combat_situation[entity]\u001b[38;5;241m.\u001b[39mActions\u001b[38;5;241m.\u001b[39mappend(Character_Actions\u001b[38;5;241m.\u001b[39mHelp_Action(combat_situation[entity],combat_situation,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "env = generate_combat(4)\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m      9\u001b[0m     action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m---> 10\u001b[0m     n_state, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Score:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(episode, score))\n",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m, in \u001b[0;36mCombatEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# apply actions\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m:\n\u001b[0;32m     18\u001b[0m         reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m states \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      2\u001b[0m actions \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, activation='relu', input_shape=states))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
